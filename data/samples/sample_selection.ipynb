{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e05f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# # Define the folder path\n",
    "# computer_villa = 'C:/Users/rli04/Villanova University/Complete-trip-coordinate - Documents/General'\n",
    "# file_paths = glob.glob(computer_villa + '/Salt_Lake/delivery/Salt_Lake-Mar-2020/*.snappy.parquet')\n",
    "# df_list = [pd.read_parquet(file, engine='pyarrow') for file in file_paths]\n",
    "# # Load the first file\n",
    "# combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1a94a",
   "metadata": {},
   "source": [
    "workflow\n",
    "1. raw data\n",
    "2. linked trip aggregation, sort by local_datetime_start\n",
    "3. select OD (airport to center city)[cences track level]\n",
    "4. linked trip filtter (the first trip O in the airport, the last trip D in the center city)\n",
    "5. attach geomery\n",
    "6. export csv (select linked trip with multi-modes or other filtter method)\n",
    "7. export json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf937a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "BASE_DIR = \"C:/Users/rli04/Villanova University/Complete-trip-coordinate - Documents/General\"\n",
    "PARQUET_DIR = f\"{BASE_DIR}/Salt_Lake/delivery\"\n",
    "TRACT_SHP = f\"{BASE_DIR}/Manuscript/Figure/Visualization-RL/2-OD patterns by census track/six_counties_track.shp\"\n",
    "\n",
    "# airport -> central city (example)\n",
    "ORIG_TRACT = \"49035114000\"#49057201900 (weber) #49035980000 (airport)\n",
    "DEST_TRACT = \"49035980000\" #49035110106 (ski)\n",
    "# 49035114000 (center)\n",
    "MONTHS = ['Jan',\n",
    "          'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "OUTPUT_CSV = \"center2air_complete_trip_samples.csv\"\n",
    "OUTPUT_JSON = \"samples_center2air.json\"\n",
    "\n",
    "KEEP_FACTOR = 2.5   # OD < 2.5 * max(route_dist) -> DROP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262213e",
   "metadata": {},
   "source": [
    "#### 1. Load raw parquet (minimal columns)\n",
    "#### 2. Clean + normalize (time, mode, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49cda62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing month Jan ===\n",
      "\n",
      "=== Processing month Feb ===\n",
      "\n",
      "=== Processing month Mar ===\n",
      "\n",
      "=== Processing month Apr ===\n",
      "\n",
      "=== Processing month May ===\n",
      "\n",
      "=== Processing month Jun ===\n",
      "\n",
      "=== Processing month Jul ===\n",
      "\n",
      "=== Processing month Aug ===\n",
      "\n",
      "=== Processing month Sep ===\n",
      "\n",
      "=== Processing month Oct ===\n",
      "\n",
      "=== Processing month Nov ===\n",
      "\n",
      "=== Processing month Dec ===\n",
      "Before OD filter, linked trips: 218277\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pygeohash as pgh\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely import wkt\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# =========================\n",
    "# UTILS\n",
    "# =========================\n",
    "def haversine_miles(lon1, lat1, lon2, lat2):\n",
    "    R = 3958.8\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def decode_gh_series(s):\n",
    "    lat, lon = zip(*s.map(pgh.decode))\n",
    "    return np.array(lat), np.array(lon)\n",
    "\n",
    "USE_COLS = [\n",
    "    \"linked_trip_id\", \"trip_id\", \"tour_id\",\n",
    "    \"travel_mode\", \"local_datetime_start\", \"local_datetime_end\",\n",
    "    \"network_distance\", \"route_distance\",\n",
    "    \"geohash7_orig\", \"geohash7_dest\",\n",
    "    \"access_stop\", \"access_stop_id\",\n",
    "    \"egress_stop\", \"egress_stop_id\",\n",
    "    \"trip_purpose\", \"trip_weight\",\n",
    "    \"route_taken\"\n",
    "]\n",
    "\n",
    "MONTHLY_DFS = []\n",
    "# =========================\n",
    "# 1Ô∏è‚É£ MONTHLY LOAD + BASIC FILTER\n",
    "# =========================\n",
    "for m in MONTHS:\n",
    "    print(f\"\\n=== Processing month {m} ===\")\n",
    "\n",
    "    files = glob.glob(f\"{PARQUET_DIR}/Salt_Lake-{m}-2020/*.snappy.parquet\")\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    dfs = [pd.read_parquet(f, columns=USE_COLS) for f in files]\n",
    "    df_month = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    df_month[\"local_datetime_start\"] = pd.to_datetime(df_month[\"local_datetime_start\"], errors=\"coerce\")\n",
    "    df_month[\"local_datetime_end\"] = pd.to_datetime(df_month[\"local_datetime_end\"], errors=\"coerce\")\n",
    "\n",
    "    df_month = df_month[df_month[\"local_datetime_end\"] > df_month[\"local_datetime_start\"]]\n",
    "\n",
    "    mode_sets = (\n",
    "        df_month\n",
    "        .groupby(\"linked_trip_id\")[\"travel_mode\"]\n",
    "        .agg(set)\n",
    "    )\n",
    "\n",
    "    valid_linked_ids = mode_sets[\n",
    "        (mode_sets.apply(len) >= 2) &\n",
    "        (mode_sets != {\"car\"})\n",
    "    ].index\n",
    "\n",
    "    df_month = df_month[df_month[\"linked_trip_id\"].isin(valid_linked_ids)]\n",
    "    # ‚úÖ ADD duration_min HERE (row-level, month scope)\n",
    "    df_month[\"duration_min\"] = (\n",
    "        df_month[\"local_datetime_end\"] - df_month[\"local_datetime_start\"]\n",
    "    ).dt.total_seconds() / 60\n",
    "\n",
    "    MONTHLY_DFS.append(df_month)\n",
    "\n",
    "# =========================\n",
    "# 2Ô∏è‚É£ YEAR CONCAT\n",
    "# =========================\n",
    "df = pd.concat(MONTHLY_DFS, ignore_index=True)\n",
    "print(\"Before OD filter, linked trips:\", df[\"linked_trip_id\"].nunique())\n",
    "\n",
    "# =========================\n",
    "# 3Ô∏è‚É£ OD vs ROUTE DISTANCE FILTERÔºàÊ†∏ÂøÉÊñ∞Â¢ûÔºâ\n",
    "# =========================\n",
    "df = df.sort_values([\"linked_trip_id\", \"local_datetime_start\"])\n",
    "\n",
    "# --- linked-trip OD ---\n",
    "od_df = (\n",
    "    df.groupby(\"linked_trip_id\")\n",
    "      .agg(\n",
    "          gh_o=(\"geohash7_orig\", \"first\"),\n",
    "          gh_d=(\"geohash7_dest\", \"last\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "lat_o, lon_o = decode_gh_series(od_df[\"gh_o\"])\n",
    "lat_d, lon_d = decode_gh_series(od_df[\"gh_d\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed905c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OD filter, linked trips: 217844\n"
     ]
    }
   ],
   "source": [
    "od_df[\"od_dist_mile\"] = haversine_miles(lon_o, lat_o, lon_d, lat_d)\n",
    "df[\"route_distance\"] = pd.to_numeric(\n",
    "    df[\"route_distance\"], errors=\"coerce\"\n",
    ")\n",
    "# --- max route distance (exclude -1) ---\n",
    "route_max = (\n",
    "    df[df[\"route_distance\"] >= 0]\n",
    "    .groupby(\"linked_trip_id\")[\"route_distance\"]\n",
    "    .max()\n",
    "    .rename(\"max_route_dist\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "od_df = od_df.merge(route_max, on=\"linked_trip_id\", how=\"left\")\n",
    "\n",
    "# --- apply rule ---\n",
    "od_df[\"keep\"] = ~(\n",
    "    od_df[\"od_dist_mile\"] < KEEP_FACTOR * od_df[\"max_route_dist\"]\n",
    ")\n",
    "\n",
    "valid_linked_ids = od_df.loc[od_df[\"keep\"], \"linked_trip_id\"]\n",
    "\n",
    "df = df[df[\"linked_trip_id\"].isin(valid_linked_ids)]\n",
    "\n",
    "print(\"After OD filter, linked trips:\", df[\"linked_trip_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbd94b",
   "metadata": {},
   "source": [
    "#### 3. Geohash ‚Üí census tract (orig / dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99013d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4Ô∏è‚É£ TRACT JOINÔºà‰øùÊåÅ‰Ω†ÂéüÈÄªËæëÔºâ\n",
    "# =========================\n",
    "tracts = gpd.read_file(TRACT_SHP).to_crs(\"EPSG:4326\")\n",
    "\n",
    "def gh_to_point(gh):\n",
    "    lat, lon = pgh.decode(gh)\n",
    "    return Point(lon, lat)\n",
    "\n",
    "gdf_o = gpd.GeoDataFrame(\n",
    "    df[[\"geohash7_orig\"]],\n",
    "    geometry=df[\"geohash7_orig\"].apply(gh_to_point),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf_d = gpd.GeoDataFrame(\n",
    "    df[[\"geohash7_dest\"]],\n",
    "    geometry=df[\"geohash7_dest\"].apply(gh_to_point),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "df[\"GEOID_orig\"] = gpd.sjoin(gdf_o, tracts, how=\"left\", predicate=\"within\")[\"GEOID\"].values\n",
    "df[\"GEOID_dest\"] = gpd.sjoin(gdf_d, tracts, how=\"left\", predicate=\"within\")[\"GEOID\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3038c",
   "metadata": {},
   "source": [
    "#### 4. Sort by linked_trip_id + time\n",
    "#### 5. Identify linked trips with:\n",
    "   - first.orig == airport tract\n",
    "   - last.dest == central tract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93c12ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"linked_trip_id\", \"local_datetime_start\"])\n",
    "\n",
    "first = df.groupby(\"linked_trip_id\").first()\n",
    "last = df.groupby(\"linked_trip_id\").last()\n",
    "\n",
    "valid_linked = first[\n",
    "    (first[\"GEOID_orig\"] == ORIG_TRACT) &\n",
    "    (last[\"GEOID_dest\"] == DEST_TRACT)\n",
    "].index\n",
    "\n",
    "df = df[df[\"linked_trip_id\"].isin(valid_linked)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14365f",
   "metadata": {},
   "source": [
    "#### 7. Attach network geometry (mode-aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94377eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load networks\n",
    "auto_links = pd.read_csv(f\"{BASE_DIR}/Salt_Lake/supplementInputs/network/auto-biggest-connected-graph/link.csv\")\n",
    "walk_links = pd.read_csv(f\"{BASE_DIR}/Salt_Lake/supplementInputs/network/walk-biggest-connected-graph/link.csv\")\n",
    "transit_links = pd.read_csv(f\"{BASE_DIR}/Salt_Lake/supplementInputs/network/UTA/link with flow.csv\")\n",
    "\n",
    "auto_dict = {\n",
    "    (int(r.from_osm_node_id), int(r.to_osm_node_id)): r.geometry\n",
    "    for r in auto_links.itertuples()\n",
    "}\n",
    "transit_dict = {\n",
    "    (int(r.from_node_id), int(r.to_node_id)): r.geometry\n",
    "    for r in transit_links.itertuples()\n",
    "}\n",
    "walk_dict = {\n",
    "    (int(r.from_osm_node_id), int(r.to_osm_node_id)): r.geometry\n",
    "    for r in walk_links.itertuples()\n",
    "}\n",
    "def build_geometry(row):\n",
    "    nodes = [int(x) for x in str(row.route_taken).split(\",\") if x.strip().isdigit()]\n",
    "    if len(nodes) < 2:\n",
    "        return None\n",
    "\n",
    "    coords = []\n",
    "    link_dict = (\n",
    "        auto_dict if row.travel_mode == \"car\"\n",
    "        else walk_dict if (row.travel_mode == \"walk/bike\")\n",
    "        else transit_dict if row.travel_mode in [\"bus\", \"rail\"]\n",
    "        else None\n",
    "    )\n",
    "    for a, b in zip(nodes[:-1], nodes[1:]):\n",
    "        if (a, b) in link_dict:\n",
    "            try:\n",
    "                geom = wkt.loads(link_dict[(a, b)])\n",
    "                coords.extend(list(geom.coords))\n",
    "            except:\n",
    "                continue\n",
    "    return LineString(coords) if len(coords) > 1 else None\n",
    "\n",
    "df[\"geometry\"] = df.apply(build_geometry, axis=1)\n",
    "df = df[df[\"geometry\"].notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b7fc7",
   "metadata": {},
   "source": [
    "#### 8. Aggregate per segment (trip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ce8a3",
   "metadata": {},
   "source": [
    "#### 9. Export:\n",
    "   - CSV (debug / archive)\n",
    "   - JSON (dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59523236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e6593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def is_finite(x):\n",
    "    return x is not None and isinstance(x, (int, float)) and math.isfinite(x)\n",
    "\n",
    "def clean_num(x):\n",
    "    return float(x) if is_finite(x) else None\n",
    "\n",
    "def safe_decode_geohash(gh):\n",
    "    try:\n",
    "        lat, lon = pgh.decode(gh)\n",
    "        if is_finite(lat) and is_finite(lon):\n",
    "            return lon, lat\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def build_route(geom):\n",
    "    if geom is None:\n",
    "        return None\n",
    "\n",
    "    coords = []\n",
    "    for lon, lat in geom.coords:\n",
    "        if not is_finite(lat) or not is_finite(lon):\n",
    "            continue\n",
    "        coords.append([float(lat), float(lon)])\n",
    "\n",
    "    if len(coords) < 2:\n",
    "        return None\n",
    "\n",
    "    # demo ÊäΩÁ®Ä\n",
    "    if len(coords) > 400:\n",
    "        coords = coords[::3]\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c834f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for r in df.itertuples():\n",
    "    route = build_route(r.geometry)\n",
    "    if route is None:\n",
    "        continue  # üö® ‰∏çÂêàÊ≥ïÁöÑÁõ¥Êé•‰∏¢ÂºÉ\n",
    "\n",
    "    o_lon, o_lat = safe_decode_geohash(r.geohash7_orig)\n",
    "    d_lon, d_lat = safe_decode_geohash(r.geohash7_dest)\n",
    "\n",
    "    sample = {\n",
    "        \"id\": str(r.trip_id),\n",
    "        \"mode\": str(r.travel_mode).lower().strip(),\n",
    "\n",
    "        \"route\": route,\n",
    "\n",
    "        \"duration_min\": clean_num(r.duration_min),\n",
    "        \"network_distance_km\": clean_num(r.network_distance),\n",
    "        \"route_distance_km\": clean_num(r.route_distance),\n",
    "\n",
    "        \"origin\": {\n",
    "            \"lon\": o_lon,\n",
    "            \"lat\": o_lat,\n",
    "            \"geohash\": r.geohash7_orig\n",
    "        },\n",
    "        \"destination\": {\n",
    "            \"lon\": d_lon,\n",
    "            \"lat\": d_lat,\n",
    "            \"geohash\": r.geohash7_dest\n",
    "        },\n",
    "\n",
    "        \"access\": {\n",
    "            \"stop_id\": clean_num(r.access_stop_id),\n",
    "            \"stop_name\": r.access_stop\n",
    "        },\n",
    "        \"egress\": {\n",
    "            \"stop_id\": clean_num(r.egress_stop_id),\n",
    "            \"stop_name\": r.egress_stop\n",
    "        },\n",
    "\n",
    "        \"meta\": {\n",
    "            \"linked_trip_id\": r.linked_trip_id,\n",
    "            \"tour_id\": r.tour_id,\n",
    "            \"purpose\": r.trip_purpose,\n",
    "            \"weight\": clean_num(r.trip_weight)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24ca2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\n",
    "    \"schema\": \"nova.complete_trip.sample.v1\",\n",
    "    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"count\": len(samples),\n",
    "    \"samples\": samples\n",
    "}\n",
    "\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out, f, indent=2, allow_nan=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
